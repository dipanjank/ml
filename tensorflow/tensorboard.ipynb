{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h1 align=\"center\">Visualizing TensorFlow: TensorBoard</h1>\n",
    "\n",
    "Tensorboard is a suite of visualization tools to simplify analysis of TensorFlow programs. \n",
    "\n",
    "We can use TensorBoard to \n",
    "\n",
    "* Visualize your TensorFlow graph \n",
    "* Plot quantitative metrics about the execution of your graph\n",
    "\n",
    "An example snapshot of TensorBoard:\n",
    "\n",
    "<img src=\"https://www.tensorflow.org/versions/r0.10/images/mnist_tensorboard.png\" />\n",
    "\n",
    "Let's attach an event logger to our OLS example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "pylab.style.use('ggplot')\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def event_logger(logdir, session):\n",
    "    \"\"\"\n",
    "    Hands out a managed tensorflow summary writer. \n",
    "    Cleans up the event log directory before every run.\n",
    "    \"\"\"\n",
    "        \n",
    "    if os.path.isdir(logdir):\n",
    "        shutil.rmtree(logdir)\n",
    "    os.makedirs(logdir)    \n",
    "    \n",
    "    writer = tf.summary.FileWriter(logdir, session.graph)\n",
    "    yield writer\n",
    "    writer.flush()\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x1 = np.random.rand(50)\n",
    "x2 = np.random.rand(50)\n",
    "y_ = 2*x1 + 3*x2 + 5\n",
    "\n",
    "X_data = np.column_stack([x1, x2, np.ones(50)])\n",
    "y_data = np.atleast_2d(y_).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging events to C:\\Temp\\ols_logs\\run_1, use \n",
      "\n",
      "\ttensorboard --logdir=C:\\Temp\\ols_logs\\run_1\n",
      "\n",
      " to start a new tensorboard session.\n",
      "Result after 50 iterations: [ 2.00304132  2.98769049  5.00414532]\n",
      "Result after 100 iterations: [ 1.99962635  2.99950617  5.00042744]\n",
      "Result after 150 iterations: [ 1.99995802  2.99995773  5.00004185]\n",
      "Result after 200 iterations: [ 1.99999586  2.99999593  5.00000408]\n",
      "Result after 250 iterations: [ 1.9999996  2.9999996  5.0000004]\n",
      "Result after 300 iterations: [ 1.99999996  2.99999996  5.00000004]\n",
      "Result after 350 iterations: [ 2.  3.  5.]\n",
      "Result after 400 iterations: [ 2.  3.  5.]\n",
      "Result after 450 iterations: [ 2.  3.  5.]\n",
      "Result after 500 iterations: [ 2.  3.  5.]\n"
     ]
    }
   ],
   "source": [
    "# Same as before, but this time with TensorBoard output\n",
    "log_event_dir = r'C:\\Temp\\ols_logs\\run_1'\n",
    "\n",
    "# This is necessary to avoid appending the tensors in our OLS example \n",
    "# repeatedly into the default graph each time this cell is re-run.\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(shape=[50, 3], dtype=np.float64, name='X')\n",
    "y = tf.placeholder(shape=[50, 1], dtype=np.float64, name='y')\n",
    "\n",
    "w = tf.Variable(np.random.rand(3, 1), dtype=np.float64, name='w')\n",
    "y_hat = tf.matmul(X, w)\n",
    "loss_func = tf.reduce_mean(tf.squared_difference(y_hat, y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.5)\n",
    "train_op = optimizer.minimize(loss_func)\n",
    "\n",
    "with tf.Session() as session:\n",
    "    \n",
    "    with event_logger(log_event_dir, session):\n",
    "        tensorboard_cmd = 'tensorboard --logdir={}'.format(log_event_dir)\n",
    "        print('Logging events to {}, use \\n\\n\\t{}\\n\\n to start a new tensorboard session.'.format(\n",
    "            log_event_dir, tensorboard_cmd))\n",
    "        \n",
    "        init_op = tf.global_variables_initializer()\n",
    "        session.run(init_op)\n",
    "\n",
    "        feed_dict = {X: X_data, y: y_data}\n",
    "        \n",
    "        for step in range(1, 501):            \n",
    "            session.run(train_op, feed_dict=feed_dict)\n",
    "            if step % 50 == 0:\n",
    "                current_w = np.squeeze(w.eval(session=session))\n",
    "                print('Result after {} iterations: {}'.format(step, current_w))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# The TensorFlow Execution Graph\n",
    "\n",
    "If we now launch tensorboard and navigate to http://localhost:6006, we'll see something like this (under the GRAPHS tab):\n",
    "\n",
    "<img src=\"tensorbord_ols_graph.PNG\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Emitting Custom Events\n",
    "\n",
    "Since we're using a Gradient Descent based optimizer to minimize the MSE, an important diagnostic information is the value of the loss fuction as a function of number of iterations. So let's add a custom event to record the value of the loss function in the TensorFlow event logger infrastructure that we can later examine with TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging events to C:\\Temp\\ols_logs\\run_2, use \n",
      "\n",
      "\ttensorboard --logdir=C:\\Temp\\ols_logs\\run_2\n",
      "\n",
      " to start a new tensorboard session.\n",
      "Result after 50 iterations: [ 2.02398364  3.01246245  4.98154503]\n",
      "Result after 100 iterations: [ 2.00185174  3.00172634  4.99821833]\n",
      "Result after 150 iterations: [ 2.00017644  3.0001725   4.9998265 ]\n",
      "Result after 200 iterations: [ 2.00001716  3.00001685  4.99998309]\n",
      "Result after 250 iterations: [ 2.00000167  3.00000164  4.99999835]\n",
      "Result after 300 iterations: [ 2.00000016  3.00000016  4.99999984]\n",
      "Result after 350 iterations: [ 2.00000002  3.00000002  4.99999998]\n",
      "Result after 400 iterations: [ 2.  3.  5.]\n",
      "Result after 450 iterations: [ 2.  3.  5.]\n",
      "Result after 500 iterations: [ 2.  3.  5.]\n"
     ]
    }
   ],
   "source": [
    "# Same as before, but this time with a TensorBoard output for the loss function\n",
    "\n",
    "log_event_dir = r'C:\\Temp\\ols_logs\\run_2'\n",
    "\n",
    "# This is necessary to avoid appending the tensors in our OLS example \n",
    "# repeatedly into the default graph each time this cell is re-run.\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(shape=[50, 3], dtype=np.float64, name='X')\n",
    "y = tf.placeholder(shape=[50, 1], dtype=np.float64, name='y')\n",
    "\n",
    "w = tf.Variable(np.random.rand(3, 1), dtype=np.float64, name='w')\n",
    "y_hat = tf.matmul(X, w)\n",
    "\n",
    "loss_func = tf.reduce_mean(tf.squared_difference(y_hat, y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.5)\n",
    "train_op = optimizer.minimize(loss_func)\n",
    "\n",
    "# Add a tensor with summary of the loss function\n",
    "loss_summary = tf.summary.scalar('loss', loss_func)\n",
    "summary_op = tf.summary.merge_all()\n",
    "\n",
    "with tf.Session() as session:\n",
    "    \n",
    "    with event_logger(log_event_dir, session) as recorder:\n",
    "        tensorboard_cmd = 'tensorboard --logdir={}'.format(log_event_dir)\n",
    "        print('Logging events to {}, use \\n\\n\\t{}\\n\\n to start a new tensorboard session.'.format(\n",
    "            log_event_dir, tensorboard_cmd))\n",
    "        \n",
    "        init_op = tf.global_variables_initializer()\n",
    "        session.run(init_op)\n",
    "\n",
    "        feed_dict = {X: X_data, y: y_data}\n",
    "        \n",
    "        for step in range(1, 501):           \n",
    "            _, summary_result = session.run([train_op, summary_op], feed_dict=feed_dict)\n",
    "            \n",
    "            if step % 10 == 0:\n",
    "                recorder.add_summary(summary_result, step)\n",
    "            \n",
    "            if step % 50 == 0:\n",
    "                current_w = np.squeeze(w.eval(session=session))\n",
    "                print('Result after {} iterations: {}'.format(step, current_w))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "After re-running with the loss function summary and re-launching tensorboard, we'll see something like this under the SCALARS tab:\n",
    "\n",
    "<img src=\"tensorbord_ols_loss_function.PNG\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging events to C:\\Temp\\ols_logs\\run_3, use \n",
      "\n",
      "\ttensorboard --logdir=C:\\Temp\\ols_logs\\run_3\n",
      "\n",
      " to start a new tensorboard session.\n",
      "Result after 50 iterations: [ 2.01872271  3.00756907  4.98660163]\n",
      "Result after 100 iterations: [ 2.00135094  3.00123684  4.99871074]\n",
      "Result after 150 iterations: [ 2.00012773  3.00012469  4.99987448]\n",
      "Result after 200 iterations: [ 2.00001242  3.00001219  4.99998777]\n",
      "Result after 250 iterations: [ 2.00000121  3.00000119  4.99999881]\n",
      "Result after 300 iterations: [ 2.00000012  3.00000012  4.99999988]\n",
      "Result after 350 iterations: [ 2.00000001  3.00000001  4.99999999]\n",
      "Result after 400 iterations: [ 2.  3.  5.]\n",
      "Result after 450 iterations: [ 2.  3.  5.]\n",
      "Result after 500 iterations: [ 2.  3.  5.]\n"
     ]
    }
   ],
   "source": [
    "# Same as before, but this time with a TensorBoard output for the loss function AND regression coefficients\n",
    "\n",
    "log_event_dir = r'C:\\Temp\\ols_logs\\run_3'\n",
    "\n",
    "# This is necessary to avoid appending the tensors in our OLS example \n",
    "# repeatedly into the default graph each time this cell is re-run.\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(shape=[50, 3], dtype=np.float64, name='X')\n",
    "y = tf.placeholder(shape=[50, 1], dtype=np.float64, name='y')\n",
    "\n",
    "w = tf.Variable(np.random.rand(3, 1), dtype=np.float64, name='w')\n",
    "y_hat = tf.matmul(X, w)\n",
    "\n",
    "loss_func = tf.reduce_mean(tf.squared_difference(y_hat, y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.5)\n",
    "train_op = optimizer.minimize(loss_func)\n",
    "\n",
    "# summary for the loss function\n",
    "loss_summary = tf.summary.scalar('loss', loss_func)\n",
    "\n",
    "# summary for w\n",
    "w_summary = tf.summary.histogram('coefficients', w)\n",
    "\n",
    "summary_op = tf.summary.merge_all()\n",
    "\n",
    "with tf.Session() as session:\n",
    "    \n",
    "    with event_logger(log_event_dir, session) as recorder:\n",
    "        tensorboard_cmd = 'tensorboard --logdir={}'.format(log_event_dir)\n",
    "        print('Logging events to {}, use \\n\\n\\t{}\\n\\n to start a new tensorboard session.'.format(\n",
    "            log_event_dir, tensorboard_cmd))\n",
    "        \n",
    "        init_op = tf.global_variables_initializer()\n",
    "        session.run(init_op)\n",
    "\n",
    "        feed_dict = {X: X_data, y: y_data}\n",
    "        \n",
    "        for step in range(1, 501):           \n",
    "            _, summary_result = session.run([train_op, summary_op], feed_dict=feed_dict)\n",
    "            \n",
    "            if step % 10 == 0:\n",
    "                recorder.add_summary(summary_result, step)\n",
    "            \n",
    "            if step % 50 == 0:\n",
    "                current_w = np.squeeze(w.eval(session=session))\n",
    "                print('Result after {} iterations: {}'.format(step, current_w))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficients - Distribution View\n",
    "\n",
    "<img src=\"tensorbord_coefficients_distributions.PNG\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficients - Histogram View (https://www.tensorflow.org/versions/r1.2/get_started/tensorboard_histograms)\n",
    "\n",
    "<img src=\"tensorbord_coefficients_histograms.PNG\" /> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
