{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognizer - CONLL 2003 English\n",
    "\n",
    "Use the CRF Implementation of sklearn-crfsuite to build a NER for the CONLL-2003 English Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import sklearn\n",
    "import scipy.stats\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def read_raw_input(filename):\n",
    "    \"\"\"Read a train/test file and return the contents as a list of list of lists. \n",
    "    \n",
    "    The innermost list is a record of 4 items, one per word.\n",
    "    The middle-level list contains all the records in one sentence.\n",
    "    \"\"\"\n",
    "    raw_train_file = os.path.join('CoNLL-2003', filename)\n",
    "\n",
    "    all_items = []\n",
    "\n",
    "    with open(raw_train_file) as fh:\n",
    "        current_item = []\n",
    "        all_items.append(current_item)\n",
    "\n",
    "        for line in fh:\n",
    "            tags = line.strip().split()\n",
    "            if len(tags) == 0 or tags[0] == '-DOCSTART-':\n",
    "                continue\n",
    "            current_item.append(tags)\n",
    "            if tags[0] == '.' and tags[1] == '.':\n",
    "                current_item = []\n",
    "                all_items.append(current_item)\n",
    "                \n",
    "    return all_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 991 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_sents = read_raw_input('eng.train')\n",
    "test_sents = read_raw_input('eng.testA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['EU', 'NNP', 'I-NP', 'I-ORG'],\n",
       " ['rejects', 'VBZ', 'I-VP', 'O'],\n",
       " ['German', 'JJ', 'I-NP', 'I-MISC'],\n",
       " ['call', 'NN', 'I-NP', 'O'],\n",
       " ['to', 'TO', 'I-VP', 'O'],\n",
       " ['boycott', 'VB', 'I-VP', 'O'],\n",
       " ['British', 'JJ', 'I-NP', 'I-MISC'],\n",
       " ['lamb', 'NN', 'I-NP', 'O'],\n",
       " ['.', '.', 'O', 'O']]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "display(train_sents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['CRICKET', 'NNP', 'I-NP', 'O'],\n",
       " ['-', ':', 'O', 'O'],\n",
       " ['LEICESTERSHIRE', 'NNP', 'I-NP', 'I-ORG'],\n",
       " ['TAKE', 'NNP', 'I-NP', 'O'],\n",
       " ['OVER', 'IN', 'I-PP', 'O'],\n",
       " ['AT', 'NNP', 'I-NP', 'O'],\n",
       " ['TOP', 'NNP', 'I-NP', 'O'],\n",
       " ['AFTER', 'NNP', 'I-NP', 'O'],\n",
       " ['INNINGS', 'NNP', 'I-NP', 'O'],\n",
       " ['VICTORY', 'NN', 'I-NP', 'O'],\n",
       " ['.', '.', 'O', 'O']]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(test_sents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df_for_sent(single_sent):\n",
    "    \"\"\"Make a DataFrame out of all the records for a single sentence.\"\"\"\n",
    "    df = pd.DataFrame(data=single_sent, columns=['word', 'pos', 'parse', 'ner'])\n",
    "    df.index.name = 'word_seq_num'\n",
    "    return df\n",
    "    \n",
    "def all_sentences(sents):\n",
    "    \"\"\"Convert the list of list of lists to a list of DataFrames.\"\"\"\n",
    "    total_df = [make_df_for_sent(s) for s in sents]\n",
    "    return total_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.68 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_sents = all_sentences(train_sents)\n",
    "test_sents  = all_sentences(test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>parse</th>\n",
       "      <th>ner</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_seq_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EU</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>I-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rejects</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>I-VP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>German</td>\n",
       "      <td>JJ</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>I-MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>call</td>\n",
       "      <td>NN</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>I-VP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>boycott</td>\n",
       "      <td>VB</td>\n",
       "      <td>I-VP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>British</td>\n",
       "      <td>JJ</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>I-MISC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lamb</td>\n",
       "      <td>NN</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 word  pos parse     ner\n",
       "word_seq_num                            \n",
       "0                  EU  NNP  I-NP   I-ORG\n",
       "1             rejects  VBZ  I-VP       O\n",
       "2              German   JJ  I-NP  I-MISC\n",
       "3                call   NN  I-NP       O\n",
       "4                  to   TO  I-VP       O\n",
       "5             boycott   VB  I-VP       O\n",
       "6             British   JJ  I-NP  I-MISC\n",
       "7                lamb   NN  I-NP       O\n",
       "8                   .    .     O       O"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(all_sents):\n",
    "    \"\"\"Return the labels for all the words in a collection of sentences.\"\"\"\n",
    "    all_labels = []\n",
    "    \n",
    "    for s_df in all_sents:\n",
    "        labels = s_df.loc[:, 'ner'].tolist()\n",
    "        all_labels.append(labels)\n",
    "        \n",
    "    return all_labels \n",
    "\n",
    "\n",
    "def word2features(i, single_sent_df):\n",
    "    \"\"\"\n",
    "    Return a dictionary of feature names and values for the word at ``word_idx`` \n",
    "    in a single sentence represented as a ``DataFrame``.\"\"\"\n",
    "    \n",
    "    word, postag = single_sent_df.iloc[i].loc[['word', 'pos']]\n",
    "    \n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1, postag1 = single_sent_df.iloc[i-1].loc[['word', 'pos']]\n",
    "        \n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < (single_sent_df.shape[0] - 1):\n",
    "        word1, postag1 = single_sent_df.iloc[i+1].loc[['word', 'pos']]\n",
    "        \n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "def sent2features(s_df):\n",
    "    \"\"\"\n",
    "    Return the feature values extracted from a single sentence.\n",
    "    \"\"\"    \n",
    "    features = s_df.index.map(lambda word_idx: word2features(word_idx, s_df))\n",
    "    return features.tolist()\n",
    "\n",
    "def get_feature_values(all_sents):\n",
    "    \"\"\"Get the feature values for all the sentences in train/test dataset.\"\"\"\n",
    "    \n",
    "    all_features = [sent2features(s) for s in all_sents]    \n",
    "    return all_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train = get_feature_values(train_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_test = get_feature_values(test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 938 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_train, y_test = get_labels(train_sents), get_labels(test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=200,\n",
    "    verbose=False,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I-ORG', 'I-MISC', 'I-PER', 'I-LOC', 'B-LOC', 'B-MISC', 'B-ORG']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(crf.classes_)\n",
    "labels.remove('O')\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\crf\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "d:\\Anaconda3\\envs\\crf\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8848009691129132"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "metrics.flat_f1_score(y_test, y_pred, average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\crf\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "d:\\Anaconda3\\envs\\crf\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC      0.000     0.000     0.000         0\n",
      "      I-LOC      0.910     0.862     0.885      2094\n",
      "     B-MISC      0.500     0.500     0.500         4\n",
      "     I-MISC      0.896     0.813     0.853      1264\n",
      "      B-ORG      0.000     0.000     0.000         0\n",
      "      I-ORG      0.864     0.825     0.844      2092\n",
      "      I-PER      0.926     0.924     0.925      3149\n",
      "\n",
      "avg / total      0.902     0.868     0.885      8603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# group B and I results\n",
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "report = metrics.flat_classification_report(y_test, y_pred, labels=sorted_labels, digits=3)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
