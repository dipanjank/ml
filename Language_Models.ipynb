{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h1 align=\"center\">Language Models</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Before we can do things with words, we need some words. Here we'll use the NLTK library to fetch a commonly used list of text files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('gutenberg')\n",
    "\n",
    "from nltk.corpus import gutenberg\n",
    "gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma',\n",
       " 'by',\n",
       " 'jane',\n",
       " 'austen',\n",
       " 'volume',\n",
       " 'i',\n",
       " 'chapter',\n",
       " 'i',\n",
       " 'emma',\n",
       " 'woodhouse']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "words = gutenberg.words('austen-emma.txt')\n",
    "\n",
    "# filter out numbers, etc.\n",
    "words = [w.lower() for w in words if re.match('^[a-zA-Z]+$', w)]\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "words can also serve as a generative model of text. We know that language is very complicated, but we can create a simplified model of language that captures part of the complexity. In the bag of words model, we ignore the order of words, but maintain their frequency. Think of it this way: take all the words from the text, and throw them into a bag. Shake the bag, and then generating a sentence consists of pulling words out of the bag one at a time. Chances are it won't be grammatical or sensible, but it will have words in roughly the right proportions. \n",
    "\n",
    "Here's a function to sample an n word sentence from a bag of words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['upon', 'hour', 'think', 'she', 'and', 'he', 'of', 'your', 'of', 'talk']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def sample(w, n=10):\n",
    "    \"\"\"Sample n words from a list of words, w.\"\"\"\n",
    "    return [random.choice(w) for _ in range(n)]\n",
    "\n",
    "sample(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## From Bag of Words to Probabilities\n",
    "\n",
    "From the bag of words, we can construct a frequency table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('to', 5239),\n",
       " ('the', 5201),\n",
       " ('and', 4896),\n",
       " ('of', 4291),\n",
       " ('i', 3178),\n",
       " ('a', 3129),\n",
       " ('it', 2528),\n",
       " ('her', 2469),\n",
       " ('was', 2398),\n",
       " ('she', 2340)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "word_counts = Counter(words)\n",
    "word_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7079"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "And from the frequency table, a probability distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4527</th>\n",
       "      <td>to</td>\n",
       "      <td>0.032420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3157</th>\n",
       "      <td>the</td>\n",
       "      <td>0.032184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>and</td>\n",
       "      <td>0.030297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3939</th>\n",
       "      <td>of</td>\n",
       "      <td>0.026553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>i</td>\n",
       "      <td>0.019666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     words     probs\n",
       "4527    to  0.032420\n",
       "3157   the  0.032184\n",
       "1603   and  0.030297\n",
       "3939    of  0.026553\n",
       "1266     i  0.019666"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def pdist(counter):\n",
    "    \"\"\"Make a probability distribution from a Counter.\"\"\"\n",
    "    n_words = sum(counter.values())\n",
    "    dist = [(word, count/n_words) for word, count in counter.items()]\n",
    "    return pd.DataFrame(data=dist, columns=['words', 'probs'])\n",
    "\n",
    "word_probs = pdist(word_counts)\n",
    "word_probs.sort_values('probs', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000049"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_probs['prob'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consolidate what we've learned so far into a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>counts</th>\n",
       "      <th>probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4527</th>\n",
       "      <td>to</td>\n",
       "      <td>5239</td>\n",
       "      <td>0.032420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3157</th>\n",
       "      <td>the</td>\n",
       "      <td>5201</td>\n",
       "      <td>0.032184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>and</td>\n",
       "      <td>4896</td>\n",
       "      <td>0.030297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3939</th>\n",
       "      <td>of</td>\n",
       "      <td>4291</td>\n",
       "      <td>0.026553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>i</td>\n",
       "      <td>3178</td>\n",
       "      <td>0.019666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     words  counts     probs\n",
       "4527    to    5239  0.032420\n",
       "3157   the    5201  0.032184\n",
       "1603   and    4896  0.030297\n",
       "3939    of    4291  0.026553\n",
       "1266     i    3178  0.019666"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def words_to_pdist(words):\n",
    "    \"\"\"Make a probability distribution from a list of words.\"\"\"\n",
    "    \n",
    "    wc = Counter(words)\n",
    "    n_words = sum(wc.values())\n",
    "    dist = [(word, count, count/n_words) for word, count in wc.items()]\n",
    "    \n",
    "    return pd.DataFrame(data=dist, columns=['words', 'counts', 'probs'])\n",
    "\n",
    "unigram_probs = words_to_pdist(words)\n",
    "unigram_probs.sort_values('probs', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the probability/count table above, can we assign a probability to a sentence?\n",
    "\n",
    "## The Bag of Words Model\n",
    "\n",
    "The bag of words model assumes all the words are independent.\n",
    "\n",
    "    P(to, the, end) = P(to)P(the)P(end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of ['to', 'the', 'end'] is [0.00000031]\n"
     ]
    }
   ],
   "source": [
    "def unigram_model(unigram_probs, sent):\n",
    "    \"\"\"Calculate unigram probability of a string of words, sent.\"\"\"    \n",
    "    idx_uni = unigram_probs.set_index('words')\n",
    "    return idx_uni.loc[sent, 'probs'].prod()\n",
    "\n",
    "sent = ['to', 'the', 'end']\n",
    "p_sent = unigram_model(unigram_probs, sent)\n",
    "\n",
    "print('Probability of %s is [%.8f]' % (sent, p_sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Bigram Model\n",
    "\n",
    "Use the Chain Rule of Probability to break down the full joint distribution\n",
    "\n",
    "$P(w_1 \\ldots w_n) = P(w_1) \\times P(w_2 \\mid w_1) \\times P(w_3 \\mid w_1 w_2) \\ldots  \\times \\ldots P(w_n \\mid w_1 \\ldots w_{n-1})$\n",
    "\n",
    "To make this more useful, we make the Markov assumption that only successive words depend on each other.\n",
    "\n",
    "$P(w_1 \\ldots w_n) = P(w_1) \\times P(w_2 \\mid w_1) \\times P(w_3 \\mid w_2) \\ldots  \\times \\ldots P(w_n \\mid w_{n-1})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>counts</th>\n",
       "      <th>probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9457</th>\n",
       "      <td>(to, be)</td>\n",
       "      <td>607</td>\n",
       "      <td>0.003756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53401</th>\n",
       "      <td>(of, the)</td>\n",
       "      <td>566</td>\n",
       "      <td>0.003502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56444</th>\n",
       "      <td>(it, was)</td>\n",
       "      <td>448</td>\n",
       "      <td>0.002772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14667</th>\n",
       "      <td>(in, the)</td>\n",
       "      <td>446</td>\n",
       "      <td>0.002760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61833</th>\n",
       "      <td>(i, am)</td>\n",
       "      <td>395</td>\n",
       "      <td>0.002444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           words  counts     probs\n",
       "9457    (to, be)     607  0.003756\n",
       "53401  (of, the)     566  0.003502\n",
       "56444  (it, was)     448  0.002772\n",
       "14667  (in, the)     446  0.002760\n",
       "61833    (i, am)     395  0.002444"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bigram_gen(words):\n",
    "    \"\"\"Given a word list, generate successive pairs of words.\"\"\"\n",
    "    for i in range(len(words)-1):\n",
    "        yield tuple(words[i:i+2])\n",
    "\n",
    "bigram_probs = words_to_pdist(bigram_gen(words))\n",
    "bigram_probs.sort_values('probs', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to calculate $P(w_i \\mid P(w_{i-1})$? This is simply count of the bigram $(w_i-1, w_{i-1})$ divided by the number of bigrams starts with $w_i$, which equals the unigram count of $w_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(be | to) is [0.00375621]\n",
      "P(or | be) is [0.00000619]\n",
      "P(not | or) is [0.00006807]\n",
      "P(to | not) is [0.00045792]\n",
      "P(be | to) is [0.00375621]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.8229838490342123e-20"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bigram_model(unigram_probs, bigram_probs, sent):\n",
    "    \"\"\"Calcuate bigram probability of a list of words, sent.\"\"\"\n",
    "    idx_uni = unigram_probs.set_index('words')\n",
    "    idx_bi = bigram_probs.set_index('words')\n",
    "    \n",
    "    p_sent = idx_uni.loc[sent[0], 'probs'] #P(sent[0])\n",
    "    \n",
    "    for w1, w2 in bigram_gen(sent):\n",
    "        p_w1_w2 = idx_bi.loc[[(w1, w2),], 'probs'].values[0]\n",
    "        print('P(%s | %s) is [%.8f]' % (w2, w1, p_w1_w2))\n",
    "        p_sent*= p_w1_w2\n",
    "                         \n",
    "    return p_sent\n",
    "\n",
    "bigram_model(unigram_probs, bigram_probs, ['to', 'be', 'or', 'not', 'to', 'be'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Words and Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
